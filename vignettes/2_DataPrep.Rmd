---
title: "Data Preparation"
pkgdown:
  as_is: true
output: 
  rmarkdown::html_document:
    number_sections: true
    toc: true
vignette: >
  %\VignetteIndexEntry{Data Preparation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This tutorial is on pre-processing for non-accelerometer data. Pre-processing is an important part of the project pipeline – we hope this will give you a lot of flexibility e.g. to decide what variables you want to work with. 

This tutorial contains: 

1.  Troubleshooting
2.	Introduction to available data
3.	Processing covariate data
4.	Processing health outcomes data
5.	Merging data files
6.  Participant withdrawals
7.  Exclusions
8.  Preprocessing
9. 	Finding out more 

# Troubleshooting 
If something is not working, speak to Rosemary – rosemary.walmsley@gtc.ox.ac.uk. 

# Introduction to available data
Different files are available from UK Biobank for different data types. We will use these files, available under `/cdtshared/wearables/health_data_files`: 

-	`ukb41733.csv`: A ‘standard’ dataset, with one line per participant. It contains most ‘straightforward’ data e.g. sex,  BMI, smoking status etc.
-	`hesin_all.csv`: Hospital Episode Statistics data. Each line is associated with an in-hospital diagnosis. 
-	`death.txt`: Death register data. This has one line per entry in the death register (almost always one line per participant who died), giving their date of death.
- `death_cause.txt`: Death register data on cause of death (multi-line per participant). 
- `withdrawals.csv`: List of participants who have withdrawn from UK Biobank.
-	`accelerometer-basic.csv`: A basic accelerometer dataset.
- `dataset-partially-processed`: A partially processed dataset, for this tutorial. 
- `dataset-with-preprocessing-done.csv`: A dataset with the steps in this tutorial (roughly) already performed, for use in the next tutorial if needed.
- `ukb41733.enc_ukb`: A copy of all UK Biobank fields from the main dataset (i.e. not accelerometry, health data etc). Not needed for a basic analysis - see further info below. 

Data should **never** be downloaded to your local machine. All data should be deleted at the end of the Data Challenge (and we will email you to confirm this).

The next session uses Python scripts. To ensure you have the appropriate dependencies, run:
```{r, engine='bash', eval = FALSE}
conda activate wearables
```
If you later want to  use RMarkdown, you might have to run: `conda deactivate`. 

# Processing covariate data
This section aims to give you an idea of how to process UK Biobank data from scratch, and to allow you to flexibly go back and consider the variables you want to use (among those available in the [UK Biobank Data Showcase](https://biobank.ndph.ox.ac.uk/ukb/)). However, **you don't need to redo this**. We have already done the steps here and saved the files for you, so you will only need to follow these steps if you want to get some different variables.

Data from UK Biobank comes in a `.enc_ukb` file, from which particular variables are extracted. Once you have an extracted `.csv` file both the column names and the variable codings need processing.

Different tools are available to help with this. We're using a repo that Shing and Rosemary have developed to get going quickly. [Read the docs](https://ukb-download-and-prep-template.readthedocs.io/en/latest/started.html) and [find it on GitHub]( https://ukb-download-and-prep-template.readthedocs.io/en/latest/download.html#downloading-participant-data).
There are usually three key steps: 

- [Installation](https://ukb-download-and-prep-template.readthedocs.io/en/latest/started.html#installation)
-	[Extracting a .csv file from the .enc_ukb file](https://ukb-download-and-prep-template.readthedocs.io/en/latest/download.html#extracting-participant-data-to-csv)
-	[Automated pre-processing of all variables]( https://ukb-download-and-prep-template.readthedocs.io/en/latest/core.html#relabelling-and-recoding-participant-data)

We've done step 2 using a generic (and large!) set of analysis variables, corresponding to those in `analysisCols.txt` in the above repo, and saved the output as `ukb41733.csv`. If you need other variables, feel free to go back and try step 2 - the `ukb41733.enc_ukb` file is available for this purpose. You will need to copy it to another folder to work with it (as the processing file needs to write to the folder it is in) and also change the permissions on `ukbconv` so it is executable (`chmod u+x ukbconv`). 

We've also done step 3 with the same set of columns: this is `dataset-partially-processed.csv` (which has also had some health data added). If you go back and do step 2 you'll have to do step 3 too. You might also jump in at step 3 if you want instances and array indices other than the first measurement at baseline assessment (see next paragraph). And it's also possible to use the csv from step 3 directly (i.e. without using our scripts).

If you are extracting new variables, **an important note**: variables in UK Biobank come with instances and array indices. In the csv file before processing, they are named as fieldnumber.instance.array_index (e.g. 2443.1.0 for the first item ("0") at the first repeat visit ("1")). For most variables, repeat 1 refers to a resurvey among a limited number of participants and repeat 2 is the imaging revisit. Both apply only to a subset of participants. More importantly, some variables have multiple items, as participants could check multiple boxes (e.g. [6138](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=6138) on qualifications) or had multiple measurements taken at a single visit (e.g. blood pressure measurements) In these cases, you'll have to [change the defaults](https://ukb-download-and-prep-template.readthedocs.io/en/latest/advanced.html) to usefully use the variables. 

Finding this hard to use? Spotted a bug? We’d love to get feedback and to make it as user-friendly as possible.

# Processing health outcomes data 
This section describes health outcome data. For this section, you can use `dataset-partially-processed.csv` (or your own output from the last section). `dataset-partially-processed.csv` has already had a lot of health outcomes added (corresponding to those in `icdGroups.json` in the above repo), but you are likely to want to add more. 
To do so, follow [these steps](https://ukb-download-and-prep-template.readthedocs.io/en/latest/core.html#adding-hospital-episode-statistics), which describes working with Hospital Episode Statistics (`hesin_all.csv`).

You will probably also want to use data on deaths, which can be found in the `death.txt` and `death_cause.txt` files. Even if mortality is not your outcome, if you are doing analyses of survival data, participants are censored at death for other outcomes. Also, sometimes a disease event may appear in the death register without appearing in Hospital Episode Statistics e.g. a fatal stroke occurring outside of hospital would be recorded on the death register but not in HES.

Censoring dates for all outcome data at time of download of these files were 31/12/20 for the death register; 31/12/20 for HES in England and Scotland, 28/02/18 for HES in Wales. To find out more about what these censoring dates mean, see https://biobank.ctsu.ox.ac.uk/crystal/exinfo.cgi?src=Data_providers_and_dates. However, note that the dataset you have access to is censored earlier than the dates listed here (it was downloaded earlier).

## Defining the outcome
One of the challenges in the Data Challenge will be working out how to define your health outcome. Some things to think about: 
- Disease codes in HES data and on the death register mostly use [ICD-10 codes](https://icd.who.int/browse10/2010/en). [Some records from the 1990s and earlier use its precursor, ICD-9, but this is a small proportion.]
- Previous papers might be a helpful source of disease definitions. 
- If you can, it's usually useful to speak to someone with clinical expertise. 
- There are some papers looking at the features of different data sources for different health outcomes e.g. [this paper on stroke](https://n.neurology.org/content/95/6/e697). [This paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3264740/) discusses contexts in which different aspects of accurate classification are important.
- HES data in UK Biobank is *inpatient* episodes only. That means that it only includes hospital visits where the participant occupied a bed (not necessarily overnight). This means Emergency Department attendances and outpatient appointments which did not result in admission will not be present in the data. This is more of an issue for some conditions than others. 
- Primary care data is available on a subset of UK Biobank participants (to be expanded to all participants eventually), but is beyond the scope of this challenge. 
- Operations and procedures codes are also available but are again beyond the scope of this challenge.
- There are some quirks to the HES data. For example, psychiatric admissions are included in English and Welsh data, but not in Scottish data. 
- If you want to learn more about HES data in UK Biobank, see [this resource](biobank.ndph.ox.ac.uk/ukb/ukb/docs/HospitalEpisodeStatistics.pdf).



# Merging data files
You can merge data files using the ‘eid’ column.

Note that with accelerometer data, the ‘eid’ column may need adjusting to remove extra text e.g. 
```{r, eval = FALSE}
# First we'll load data.table, a package that makes reading large files easier
if (!require("data.table")) install.packages("data.table")
library(data.table)

# Then we load acc data and covariate data
acc <- data.frame(fread("/cdtshared/wearables/health_data_files/accelerometer-basic.csv"))
df <- data.frame(fread("/cdtshared/wearables/health_data_files/dataset-partially-processed.csv"))

# Then we relabel eids to same format
acc$eid <- gsub("_90001_0_0.gz", "", acc$eid) # This line replaces the first string with the second one wherever it appears in acc$eid

# Then we merge
df <- merge(df, acc, by = "eid")
```

# Withdrawals 
Participants have the right to withdraw at any time from UK Biobank. For participants who withdrew between the dataset being generated and it being used, we need to withdraw them manually. 
```{r, eval = FALSE}
nrow(df)
w <- read.csv("/cdtshared/wearables/health_data_files/withdrawals.csv", header = FALSE)
df <- df[!(df$eid %in% w$V1),  ]
nrow(df)
```

# Exclusions 
Before working with the data, we usually exclude some participants. 

First, we exclude participants with poor quality accelerometer data. A standard protocol for exclusions in UK Biobank is to: 

- Exclude participants whose device could not be calibrated: 
```{r, eval = FALSE}
df <- df[df$quality.goodCalibration ==1, ]
```

- Exclude participants who had <3 days wear or did not have wear in each hour of the 24 hour day: 
```{r, eval = FALSE}
df <- df[df$quality.goodWearTime == 1, ]
```
- Exclude participants for whom >1% of values were clipped (fell outside the sensor's range) before or after calibration: 

```{r, eval = FALSE}
df <- df[(df$clipsBeforeCalibration < 0.01*df$totalReads) & (df$clipsAfterCalibration <0.01*df$totalReads) , ]
```

- Exclude participants with unrealistically high average acceleration values: 
```{r, eval = FALSE}
df <- df[df$acc.overall.avg < 100, ]
```

If you're interested in finding out more [this is a good reference](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169649). There is a lot of literature on accelerometer data quality! 

There are two other types of exclusions you may wish to make, depending on your planned analysis. These can be done now, or later:

- Health-related exclusions. For example, if you are analysing incident disease, you may wish to exclude people who had prevalent disease at the time they wore the accelerometer. 
- Missing covariate data. If small numbers of participants have missing data in covariates, you may wish to exclude them. (Alternatively, you could look into missing data imputation). 

**Important:** You should record how many participants were excluded at each of the above steps. Usually, studies present a [flow diagram](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0040297) (see point 13c) to be precise about which groups of participants were left out and why. 

**Watch out for NA values** Lots of the R code in these tutorials [will do some very weird things if you have `NA` values in variables](https://www.r-bloggers.com/2018/10/subsetting-in-the-presence-of-nas/). Have a look and check it's behaving as you expect. 

# Preprocessing 

As described above the data has had some rough preprocessing already performed, corresponding to use of the UK Biobank data dictionary to recode variables. However, this is automated and imperfect. For example, some numeric variables may have special values indicating missing data, which have not been automatically processed (an example is [fresh fruit intake](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=1309)).

Now is a good time to look at the variables you're planning to use in more detail, understand their distribution, recode any values you wish to recode, and change groupings as required. For example, the [ethnicity variable](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=21000) has many distinctions, some of which apply to very few participants, so you may wish to recode it for statistical analyses. Spending time understanding the data in detail now will not be wasted!

The [UK Biobank Data Showcase](https://biobank.ndph.ox.ac.uk/showcase/search.cgi) is the go-to resource for understanding variables in the data.

One thing you will need to do is add an age-at-accelerometer-wear variable. Here's an example of some code to do that: 
```{r, eval = FALSE}
# ADD DATE OF BIRTH
df$approx_dob <-
  as.Date(paste(df$YearOfBirth, df$MonthOfBirth, "15", sep = "-"),
          "%Y-%B-%d") # UK Biobank doesn't contain day of birth as it would be unnecessary identifying information, so we impute it as the 15th of the birth month. 

# ENSURE DATES FORMATTED CORRECTLY
df$end_accel_wear <- as.Date(df$EndTimWear, "%Y-%m-%d %H:%M:%S", tz = "Europe/London")

# ADD AGE AT ENTRY IN DAYS
df$age_entry_days <-
  difftime(df$end_accel_wear, 
           df$approx_dob,
           units = "days")

# CONVERT TO AGE AT ENTRY IN YEARS
df$age_entry_years <- as.numeric(df$age_entry_days)/365.25

# ADD AGE GROUPS
df$broadAgeGroup <- cut(df$age_entry_years, breaks = c(40, 50, 60, 70, 80 ), right = FALSE, labels = c("40-49", "50-59", "60-69", "70-79"))

```

If you're interested in incident disease analyses, you might also want to add a follow-up time variable i.e. the difference between the time the participant entered the study (accelerometer wear date) and when they left it: death, censoring (end date of study data, at which point they had not had an event) or the event of interest. The next tutorial contains an example.

Remember to write your prepared dataset to a file so that you can use it again!

# Finding out more

To find out more about particular UK Biobank variables, use the [Data Showcase](https://biobank.ndph.ox.ac.uk/ukb/)

To find out more about UK Biobank data collection and history, [this](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001779) is a good summary

In addition to what we’ve shared here, UK Biobank is an open resource and several other open-source tools are available to support its use ([an example](https://git.fmrib.ox.ac.uk/fsl/funpack))

UK Biobank is currently moving to an [Amazon Web Services model](https://www.ukbiobank.ac.uk/learn-more-about-uk-biobank/news/uk-biobank-creates-cloud-based-health-data-analysis-platform-to-unleash-the-imaginations-of-the-world-s-best-scientific-minds). In the future, this will likely represent the best way to access UK Biobank data. 
